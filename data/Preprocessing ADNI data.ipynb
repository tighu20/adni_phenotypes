{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing ADNI data\n",
    "\n",
    "## 1st part - Dividing in train/val sets, and correct for confounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as smf\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "demo_cols = ['diagnosis', 'age', 'gender', 'eTIV']\n",
    "\n",
    "features_cort = ['thickness_bankssts_lh',  'thickness_caudalanteriorcingulate_lh', 'thickness_caudalmiddlefrontal_lh',  'thickness_cuneus_lh',  'thickness_entorhinal_lh',  'thickness_fusiform_lh',  'thickness_inferiorparietal_lh',  'thickness_inferiortemporal_lh',  'thickness_isthmuscingulate_lh',  'thickness_lateraloccipital_lh',  'thickness_lateralorbitofrontal_lh',  'thickness_lingual_lh',  'thickness_medialorbitofrontal_lh',  'thickness_middletemporal_lh',  'thickness_parahippocampal_lh',  'thickness_paracentral_lh',  'thickness_parsopercularis_lh',  'thickness_parsorbitalis_lh',  'thickness_parstriangularis_lh',  'thickness_pericalcarine_lh',  'thickness_postcentral_lh',  'thickness_posteriorcingulate_lh',  'thickness_precentral_lh',  'thickness_precuneus_lh',  'thickness_rostralanteriorcingulate_lh', 'thickness_rostralmiddlefrontal_lh',  'thickness_superiorfrontal_lh',  'thickness_superiorparietal_lh',  'thickness_superiortemporal_lh',  'thickness_supramarginal_lh',  'thickness_frontalpole_lh',  'thickness_temporalpole_lh',  'thickness_transversetemporal_lh',  'thickness_insula_lh',  'thickness_bankssts_rh',  'thickness_caudalanteriorcingulate_rh', 'thickness_caudalmiddlefrontal_rh',  'thickness_cuneus_rh',  'thickness_entorhinal_rh',  'thickness_fusiform_rh',  'thickness_inferiorparietal_rh',  'thickness_inferiortemporal_rh',  'thickness_isthmuscingulate_rh',  'thickness_lateraloccipital_rh',  'thickness_lateralorbitofrontal_rh',  'thickness_lingual_rh',  'thickness_medialorbitofrontal_rh',  'thickness_middletemporal_rh',  'thickness_parahippocampal_rh',  'thickness_paracentral_rh',  'thickness_parsopercularis_rh',  'thickness_parsorbitalis_rh',  'thickness_parstriangularis_rh',  'thickness_pericalcarine_rh',  'thickness_postcentral_rh',  'thickness_posteriorcingulate_rh',  'thickness_precentral_rh',  'thickness_precuneus_rh',  'thickness_rostralanteriorcingulate_rh', 'thickness_rostralmiddlefrontal_rh',  'thickness_superiorfrontal_rh',  'thickness_superiorparietal_rh',  'thickness_superiortemporal_rh',  'thickness_supramarginal_rh',  'thickness_frontalpole_rh',  'thickness_temporalpole_rh',  'thickness_transversetemporal_rh',  'thickness_insula_rh']\n",
    "\n",
    "features_vol = ['volume_bankssts_lh', 'volume_caudalanteriorcingulate_lh', 'volume_caudalmiddlefrontal_lh', 'volume_cuneus_lh', 'volume_entorhinal_lh', 'volume_fusiform_lh', 'volume_inferiorparietal_lh', 'volume_inferiortemporal_lh', 'volume_isthmuscingulate_lh', 'volume_lateraloccipital_lh', 'volume_lateralorbitofrontal_lh', 'volume_lingual_lh', 'volume_medialorbitofrontal_lh', 'volume_middletemporal_lh', 'volume_parahippocampal_lh', 'volume_paracentral_lh', 'volume_parsopercularis_lh', 'volume_parsorbitalis_lh', 'volume_parstriangularis_lh', 'volume_pericalcarine_lh', 'volume_postcentral_lh', 'volume_posteriorcingulate_lh', 'volume_precentral_lh', 'volume_precuneus_lh', 'volume_rostralanteriorcingulate_lh', 'volume_rostralmiddlefrontal_lh', 'volume_superiorfrontal_lh', 'volume_superiorparietal_lh', 'volume_superiortemporal_lh', 'volume_supramarginal_lh', 'volume_frontalpole_lh', 'volume_temporalpole_lh', 'volume_transversetemporal_lh', 'volume_insula_lh', 'volume_bankssts_rh', 'volume_caudalanteriorcingulate_rh', 'volume_caudalmiddlefrontal_rh', 'volume_cuneus_rh', 'volume_entorhinal_rh', 'volume_fusiform_rh', 'volume_inferiorparietal_rh', 'volume_inferiortemporal_rh', 'volume_isthmuscingulate_rh', 'volume_lateraloccipital_rh', 'volume_lateralorbitofrontal_rh', 'volume_lingual_rh', 'volume_medialorbitofrontal_rh', 'volume_middletemporal_rh', 'volume_parahippocampal_rh', 'volume_paracentral_rh', 'volume_parsopercularis_rh', 'volume_parsorbitalis_rh', 'volume_parstriangularis_rh', 'volume_pericalcarine_rh', 'volume_postcentral_rh', 'volume_posteriorcingulate_rh', 'volume_precentral_rh', 'volume_precuneus_rh', 'volume_rostralanteriorcingulate_rh', 'volume_rostralmiddlefrontal_rh', 'volume_superiorfrontal_rh', 'volume_superiorparietal_rh', 'volume_superiortemporal_rh', 'volume_supramarginal_rh', 'volume_frontalpole_rh', 'volume_temporalpole_rh', 'volume_transversetemporal_rh', 'volume_insula_rh']\n",
    "\n",
    "features_vol_extra = ['volume_Left-Cerebellum-White-Matter', 'volume_Left-Cerebellum-Cortex',\n",
    "                      'volume_Left-Thalamus-Proper', 'volume_Left-Caudate', 'volume_Left-Putamen',\n",
    "                      'volume_Left-Pallidum','volume_Brain-Stem', 'volume_Left-Hippocampus', \n",
    "                      'volume_Left-Amygdala', 'volume_Left-Accumbens-area', 'volume_Right-Cerebellum-White-Matter',\n",
    "                      'volume_Right-Cerebellum-Cortex', 'volume_Right-Thalamus-Proper', 'volume_Right-Caudate',\n",
    "                      'volume_Right-Putamen', 'volume_Right-Pallidum', 'volume_Right-Hippocampus', \n",
    "                      'volume_Right-Amygdala', 'volume_Right-Accumbens-area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: (736, 185)\n",
      "After (736, 159)\n"
     ]
    }
   ],
   "source": [
    "df_adni = pd.read_csv('raw_collated_freesurfer.csv', sep='\\t', index_col=0)\n",
    "print('Before:', df_adni.shape)\n",
    "\n",
    "# Removing unnecessary volume columns like ventricles, hypointensities, CC_, and others\n",
    "df_adni = df_adni.loc[:, demo_cols + features_cort + features_vol + features_vol_extra]\n",
    "\n",
    "print('After', df_adni.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting all the demographic values to stratitfy dataset according to them\n",
    "confounds = {'diagnosis' : [], 'age' : [], 'gender' : [], 'eTIV' : []}\n",
    "             \n",
    "for i in range(df_adni.shape[0]):\n",
    "    for confound in confounds.keys():\n",
    "        confounds[confound].append(df_adni.at[df_adni.index[i], confound])\n",
    "        \n",
    "# Making age and eTIV bucketised each in 5 blocks\n",
    "confounds['age'] = pd.qcut(confounds['age'], 5, labels=False)\n",
    "confounds['eTIV'] = pd.qcut(confounds['eTIV'], 5, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "662 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/sdc/tmla2/miniconda/envs/adni_tim/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    }
   ],
   "source": [
    "# Joining all the demographic values in str-format labels, and then use LabelEncoder() to change to int-format labels\n",
    "joined_labels = [f'{confounds[\"diagnosis\"][i]}{confounds[\"age\"][i]}{confounds[\"gender\"][i]}{confounds[\"eTIV\"][i]}' for i in range(df_adni.shape[0])]\n",
    "\n",
    "strat_labels = LabelEncoder().fit_transform(joined_labels)\n",
    "\n",
    "# ~10% test set\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1111)\n",
    "skf_generator = skf.split(np.zeros((df_adni.shape[0], 1)), strat_labels)\n",
    "\n",
    "for train_index, test_index in skf_generator:\n",
    "    print(len(train_index), len(test_index))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "        34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "        51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
       "        68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
       "        85, 86, 87, 88, 89, 90, 91, 92, 93]),\n",
       " array([15, 12,  7,  3,  1,  4,  6,  9, 21, 15,  4,  8,  3,  1,  2,  5,  3,\n",
       "        11,  7,  5,  7,  4,  1,  3,  4,  5,  6, 11, 11, 10,  4,  4,  1,  5,\n",
       "         6, 11, 14, 14,  7,  5,  2,  4,  8, 11, 17, 14, 15, 14,  8,  3,  2,\n",
       "         4,  2,  3, 11,  9, 16, 14, 12,  6,  2,  2,  7, 15, 16,  7, 14, 12,\n",
       "        12,  6,  3,  2,  2,  7, 17, 16, 15, 17,  7,  2,  1,  3, 10, 11, 16,\n",
       "         7,  9,  4,  2,  3,  6,  5, 13, 15]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quickly check distribution of all the \"joined\" labels\n",
    "np.unique(strat_labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing the original raw df\n",
    "df_train = df_adni.iloc[train_index, :].copy()\n",
    "df_test = df_adni.iloc[test_index, :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_residuals(indep_vars, data, columns, name_regress):\n",
    "    for c in columns:\n",
    "        mod = smf.OLS.from_formula(formula= f'Q(\"{c}\") ~ {indep_vars}', data=data)\n",
    "        model = mod.fit()\n",
    "\n",
    "        data.loc[:, c] = model.resid\n",
    "        \n",
    "        model.save(f'../regress_models/{name_regress}_{c}.pkl')\n",
    "        \n",
    "def calculate_residuals(data, columns, name_regress):\n",
    "    for c in columns:\n",
    "        lin_model = smf.load(f'../regress_models/{name_regress}_{c}.pkl')\n",
    "        \n",
    "        data[c] = data[c] - lin_model.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate residuals from train data (fit curve and save model)\n",
    "populate_residuals(indep_vars='age', data=df_train, columns=features_cort, name_regress='adni')\n",
    "populate_residuals(indep_vars='age + eTIV + C(gender)', data=df_train, columns=features_vol+features_vol_extra, name_regress='adni')\n",
    "\n",
    "# Calculate residuals for test data (load model and calculate from previously fitted curve)\n",
    "calculate_residuals(data=df_test, columns=features_cort, name_regress='adni')\n",
    "calculate_residuals(data=df_test, columns=features_vol+features_vol_extra, name_regress='adni')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Saving corrected data\n",
    "df_train.to_csv('adni_train_corrected.csv')\n",
    "df_test.to_csv('adni_test_corrected.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd part - Normalise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib \n",
    "\n",
    "demo_cols = ['diagnosis', 'age', 'gender', 'eTIV']\n",
    "\n",
    "features_cort = ['thickness_bankssts_lh',  'thickness_caudalanteriorcingulate_lh', 'thickness_caudalmiddlefrontal_lh',  'thickness_cuneus_lh',  'thickness_entorhinal_lh',  'thickness_fusiform_lh',  'thickness_inferiorparietal_lh',  'thickness_inferiortemporal_lh',  'thickness_isthmuscingulate_lh',  'thickness_lateraloccipital_lh',  'thickness_lateralorbitofrontal_lh',  'thickness_lingual_lh',  'thickness_medialorbitofrontal_lh',  'thickness_middletemporal_lh',  'thickness_parahippocampal_lh',  'thickness_paracentral_lh',  'thickness_parsopercularis_lh',  'thickness_parsorbitalis_lh',  'thickness_parstriangularis_lh',  'thickness_pericalcarine_lh',  'thickness_postcentral_lh',  'thickness_posteriorcingulate_lh',  'thickness_precentral_lh',  'thickness_precuneus_lh',  'thickness_rostralanteriorcingulate_lh', 'thickness_rostralmiddlefrontal_lh',  'thickness_superiorfrontal_lh',  'thickness_superiorparietal_lh',  'thickness_superiortemporal_lh',  'thickness_supramarginal_lh',  'thickness_frontalpole_lh',  'thickness_temporalpole_lh',  'thickness_transversetemporal_lh',  'thickness_insula_lh',  'thickness_bankssts_rh',  'thickness_caudalanteriorcingulate_rh', 'thickness_caudalmiddlefrontal_rh',  'thickness_cuneus_rh',  'thickness_entorhinal_rh',  'thickness_fusiform_rh',  'thickness_inferiorparietal_rh',  'thickness_inferiortemporal_rh',  'thickness_isthmuscingulate_rh',  'thickness_lateraloccipital_rh',  'thickness_lateralorbitofrontal_rh',  'thickness_lingual_rh',  'thickness_medialorbitofrontal_rh',  'thickness_middletemporal_rh',  'thickness_parahippocampal_rh',  'thickness_paracentral_rh',  'thickness_parsopercularis_rh',  'thickness_parsorbitalis_rh',  'thickness_parstriangularis_rh',  'thickness_pericalcarine_rh',  'thickness_postcentral_rh',  'thickness_posteriorcingulate_rh',  'thickness_precentral_rh',  'thickness_precuneus_rh',  'thickness_rostralanteriorcingulate_rh', 'thickness_rostralmiddlefrontal_rh',  'thickness_superiorfrontal_rh',  'thickness_superiorparietal_rh',  'thickness_superiortemporal_rh',  'thickness_supramarginal_rh',  'thickness_frontalpole_rh',  'thickness_temporalpole_rh',  'thickness_transversetemporal_rh',  'thickness_insula_rh']\n",
    "\n",
    "features_vol = ['volume_bankssts_lh', 'volume_caudalanteriorcingulate_lh', 'volume_caudalmiddlefrontal_lh', 'volume_cuneus_lh', 'volume_entorhinal_lh', 'volume_fusiform_lh', 'volume_inferiorparietal_lh', 'volume_inferiortemporal_lh', 'volume_isthmuscingulate_lh', 'volume_lateraloccipital_lh', 'volume_lateralorbitofrontal_lh', 'volume_lingual_lh', 'volume_medialorbitofrontal_lh', 'volume_middletemporal_lh', 'volume_parahippocampal_lh', 'volume_paracentral_lh', 'volume_parsopercularis_lh', 'volume_parsorbitalis_lh', 'volume_parstriangularis_lh', 'volume_pericalcarine_lh', 'volume_postcentral_lh', 'volume_posteriorcingulate_lh', 'volume_precentral_lh', 'volume_precuneus_lh', 'volume_rostralanteriorcingulate_lh', 'volume_rostralmiddlefrontal_lh', 'volume_superiorfrontal_lh', 'volume_superiorparietal_lh', 'volume_superiortemporal_lh', 'volume_supramarginal_lh', 'volume_frontalpole_lh', 'volume_temporalpole_lh', 'volume_transversetemporal_lh', 'volume_insula_lh', 'volume_bankssts_rh', 'volume_caudalanteriorcingulate_rh', 'volume_caudalmiddlefrontal_rh', 'volume_cuneus_rh', 'volume_entorhinal_rh', 'volume_fusiform_rh', 'volume_inferiorparietal_rh', 'volume_inferiortemporal_rh', 'volume_isthmuscingulate_rh', 'volume_lateraloccipital_rh', 'volume_lateralorbitofrontal_rh', 'volume_lingual_rh', 'volume_medialorbitofrontal_rh', 'volume_middletemporal_rh', 'volume_parahippocampal_rh', 'volume_paracentral_rh', 'volume_parsopercularis_rh', 'volume_parsorbitalis_rh', 'volume_parstriangularis_rh', 'volume_pericalcarine_rh', 'volume_postcentral_rh', 'volume_posteriorcingulate_rh', 'volume_precentral_rh', 'volume_precuneus_rh', 'volume_rostralanteriorcingulate_rh', 'volume_rostralmiddlefrontal_rh', 'volume_superiorfrontal_rh', 'volume_superiorparietal_rh', 'volume_superiortemporal_rh', 'volume_supramarginal_rh', 'volume_frontalpole_rh', 'volume_temporalpole_rh', 'volume_transversetemporal_rh', 'volume_insula_rh']\n",
    "\n",
    "features_vol_extra = ['volume_Left-Cerebellum-White-Matter', 'volume_Left-Cerebellum-Cortex',\n",
    "                      'volume_Left-Thalamus-Proper', 'volume_Left-Caudate', 'volume_Left-Putamen',\n",
    "                      'volume_Left-Pallidum','volume_Brain-Stem', 'volume_Left-Hippocampus', \n",
    "                      'volume_Left-Amygdala', 'volume_Left-Accumbens-area', 'volume_Right-Cerebellum-White-Matter',\n",
    "                      'volume_Right-Cerebellum-Cortex', 'volume_Right-Thalamus-Proper', 'volume_Right-Caudate',\n",
    "                      'volume_Right-Putamen', 'volume_Right-Pallidum', 'volume_Right-Hippocampus', \n",
    "                      'volume_Right-Amygdala', 'volume_Right-Accumbens-area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_adni_df(df_name):\n",
    "    df_adni = pd.read_csv(df_name, index_col=0)\n",
    "    y = df_adni['diagnosis'].copy()\n",
    "    # Ensuring this order in all dataframes for correct correction when scaling\n",
    "    df_adni = df_adni[features_cort + features_vol + features_vol_extra]\n",
    "    \n",
    "    y[y == 'Control'] = 0\n",
    "    y[y == 'AD'] = 1\n",
    "    \n",
    "    # Just checking the shape is ok\n",
    "    assert df_adni.shape[1] == len(features_cort + features_vol + features_vol_extra), 'Something is wrong with dataframe shape!'\n",
    "    assert sorted(y.unique()) == [0, 1], 'Something is wrong with dataframe shape!'\n",
    "    \n",
    "    return df_adni, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = strip_adni_df('adni_train_corrected.csv')\n",
    "X_test, y_test = strip_adni_df('adni_test_corrected.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">0, train: min=-3.637, max=2.753, test: min=-2.013, max=2.347\n",
      ">1, train: min=-4.384, max=2.673, test: min=-2.128, max=2.177\n",
      ">2, train: min=-4.617, max=2.358, test: min=-2.273, max=1.554\n",
      ">3, train: min=-3.598, max=3.415, test: min=-3.312, max=3.363\n",
      ">4, train: min=-3.362, max=2.381, test: min=-2.218, max=1.525\n",
      ">5, train: min=-4.799, max=2.188, test: min=-3.132, max=1.750\n",
      ">6, train: min=-3.417, max=2.312, test: min=-3.072, max=1.861\n",
      ">7, train: min=-3.776, max=2.537, test: min=-3.244, max=2.077\n",
      ">8, train: min=-3.433, max=3.377, test: min=-1.892, max=2.500\n",
      ">9, train: min=-3.360, max=2.975, test: min=-4.645, max=2.072\n",
      ">10, train: min=-4.410, max=4.430, test: min=-2.624, max=2.811\n",
      ">11, train: min=-3.720, max=3.244, test: min=-3.585, max=2.130\n",
      ">12, train: min=-4.272, max=3.500, test: min=-2.928, max=2.571\n",
      ">13, train: min=-4.266, max=2.530, test: min=-1.991, max=1.442\n",
      ">14, train: min=-2.809, max=2.868, test: min=-2.169, max=2.871\n",
      ">15, train: min=-3.653, max=2.604, test: min=-3.109, max=2.422\n",
      ">16, train: min=-3.810, max=3.149, test: min=-2.009, max=1.601\n",
      ">17, train: min=-3.214, max=4.792, test: min=-2.368, max=1.859\n",
      ">18, train: min=-3.408, max=3.940, test: min=-2.001, max=2.393\n",
      ">19, train: min=-2.430, max=4.580, test: min=-2.123, max=3.125\n",
      ">20, train: min=-2.915, max=2.643, test: min=-2.834, max=2.243\n",
      ">21, train: min=-3.627, max=2.448, test: min=-2.852, max=2.076\n",
      ">22, train: min=-3.683, max=2.136, test: min=-2.880, max=2.179\n",
      ">23, train: min=-3.254, max=3.288, test: min=-2.415, max=2.386\n",
      ">24, train: min=-2.985, max=4.367, test: min=-3.955, max=1.694\n",
      ">25, train: min=-4.487, max=3.254, test: min=-2.269, max=1.794\n",
      ">26, train: min=-4.191, max=2.897, test: min=-2.644, max=2.214\n",
      ">27, train: min=-3.029, max=2.985, test: min=-3.008, max=1.916\n",
      ">28, train: min=-4.093, max=2.374, test: min=-2.285, max=1.434\n",
      ">29, train: min=-3.232, max=2.467, test: min=-2.267, max=1.621\n",
      ">30, train: min=-3.132, max=3.111, test: min=-2.801, max=3.453\n",
      ">31, train: min=-4.197, max=2.265, test: min=-2.551, max=1.834\n",
      ">32, train: min=-2.872, max=3.216, test: min=-2.833, max=2.016\n",
      ">33, train: min=-3.970, max=2.873, test: min=-2.734, max=1.720\n",
      ">34, train: min=-3.603, max=3.087, test: min=-2.617, max=2.354\n",
      ">35, train: min=-2.630, max=4.290, test: min=-1.878, max=2.308\n",
      ">36, train: min=-4.068, max=2.423, test: min=-2.519, max=2.344\n",
      ">37, train: min=-2.604, max=2.867, test: min=-2.637, max=2.127\n",
      ">38, train: min=-3.147, max=2.417, test: min=-1.969, max=1.764\n",
      ">39, train: min=-4.356, max=2.335, test: min=-2.829, max=2.187\n",
      ">40, train: min=-3.677, max=2.559, test: min=-3.477, max=2.199\n",
      ">41, train: min=-3.630, max=2.350, test: min=-3.888, max=1.847\n",
      ">42, train: min=-2.756, max=3.537, test: min=-2.166, max=1.955\n",
      ">43, train: min=-3.679, max=2.844, test: min=-4.444, max=1.841\n",
      ">44, train: min=-2.885, max=3.036, test: min=-2.930, max=2.350\n",
      ">45, train: min=-2.963, max=3.544, test: min=-2.851, max=2.377\n",
      ">46, train: min=-3.749, max=4.356, test: min=-3.299, max=2.119\n",
      ">47, train: min=-3.874, max=2.087, test: min=-3.386, max=1.817\n",
      ">48, train: min=-2.921, max=2.352, test: min=-3.883, max=1.799\n",
      ">49, train: min=-3.181, max=3.390, test: min=-2.639, max=2.521\n",
      ">50, train: min=-4.543, max=2.546, test: min=-3.350, max=2.696\n",
      ">51, train: min=-3.037, max=3.374, test: min=-2.842, max=2.002\n",
      ">52, train: min=-3.330, max=2.708, test: min=-2.452, max=2.131\n",
      ">53, train: min=-3.110, max=4.763, test: min=-1.901, max=3.137\n",
      ">54, train: min=-2.924, max=2.903, test: min=-2.487, max=2.157\n",
      ">55, train: min=-5.048, max=2.963, test: min=-2.634, max=2.008\n",
      ">56, train: min=-4.167, max=2.506, test: min=-3.242, max=2.211\n",
      ">57, train: min=-3.586, max=2.422, test: min=-2.421, max=1.979\n",
      ">58, train: min=-3.266, max=3.352, test: min=-2.898, max=1.979\n",
      ">59, train: min=-3.456, max=2.666, test: min=-2.534, max=2.289\n",
      ">60, train: min=-4.080, max=2.496, test: min=-2.542, max=1.528\n",
      ">61, train: min=-3.304, max=3.538, test: min=-2.940, max=1.766\n",
      ">62, train: min=-3.257, max=3.155, test: min=-2.460, max=1.991\n",
      ">63, train: min=-3.179, max=3.166, test: min=-3.075, max=1.836\n",
      ">64, train: min=-3.129, max=3.671, test: min=-2.608, max=5.015\n",
      ">65, train: min=-3.720, max=2.187, test: min=-3.687, max=1.656\n",
      ">66, train: min=-3.336, max=2.826, test: min=-2.496, max=1.875\n",
      ">67, train: min=-3.766, max=3.482, test: min=-3.014, max=2.115\n",
      ">68, train: min=-3.150, max=3.490, test: min=-2.215, max=2.872\n",
      ">69, train: min=-2.977, max=3.184, test: min=-2.111, max=3.130\n",
      ">70, train: min=-3.222, max=3.499, test: min=-2.569, max=2.357\n",
      ">71, train: min=-3.517, max=3.287, test: min=-2.382, max=3.579\n",
      ">72, train: min=-3.517, max=4.104, test: min=-1.861, max=3.873\n",
      ">73, train: min=-3.977, max=3.069, test: min=-2.726, max=2.212\n",
      ">74, train: min=-3.421, max=2.906, test: min=-2.901, max=1.870\n",
      ">75, train: min=-4.040, max=3.026, test: min=-2.107, max=3.044\n",
      ">76, train: min=-3.800, max=4.203, test: min=-2.881, max=2.131\n",
      ">77, train: min=-3.095, max=4.691, test: min=-4.373, max=1.803\n",
      ">78, train: min=-4.294, max=2.991, test: min=-1.997, max=1.796\n",
      ">79, train: min=-3.180, max=3.030, test: min=-2.306, max=2.842\n",
      ">80, train: min=-2.755, max=4.031, test: min=-1.998, max=2.576\n",
      ">81, train: min=-3.753, max=3.324, test: min=-1.950, max=2.053\n",
      ">82, train: min=-2.880, max=3.521, test: min=-1.936, max=2.725\n",
      ">83, train: min=-2.934, max=3.875, test: min=-2.714, max=3.382\n",
      ">84, train: min=-2.918, max=7.095, test: min=-1.767, max=2.871\n",
      ">85, train: min=-3.583, max=3.341, test: min=-1.845, max=2.688\n",
      ">86, train: min=-3.373, max=3.174, test: min=-1.945, max=2.496\n",
      ">87, train: min=-2.594, max=3.315, test: min=-1.748, max=2.240\n",
      ">88, train: min=-2.466, max=3.416, test: min=-2.584, max=2.268\n",
      ">89, train: min=-4.667, max=3.266, test: min=-2.102, max=2.968\n",
      ">90, train: min=-2.925, max=3.093, test: min=-2.408, max=2.460\n",
      ">91, train: min=-3.846, max=3.487, test: min=-2.699, max=2.720\n",
      ">92, train: min=-3.701, max=4.342, test: min=-1.864, max=2.574\n",
      ">93, train: min=-3.639, max=3.827, test: min=-1.614, max=3.656\n",
      ">94, train: min=-3.714, max=2.995, test: min=-2.203, max=3.495\n",
      ">95, train: min=-3.729, max=4.007, test: min=-2.868, max=2.030\n",
      ">96, train: min=-3.858, max=3.027, test: min=-1.862, max=1.806\n",
      ">97, train: min=-2.750, max=3.007, test: min=-1.611, max=3.070\n",
      ">98, train: min=-2.461, max=3.661, test: min=-2.005, max=2.097\n",
      ">99, train: min=-3.511, max=2.662, test: min=-1.947, max=2.124\n",
      ">100, train: min=-2.272, max=3.905, test: min=-2.168, max=2.446\n",
      ">101, train: min=-4.884, max=3.688, test: min=-2.461, max=3.669\n",
      ">102, train: min=-3.051, max=4.640, test: min=-2.745, max=3.361\n",
      ">103, train: min=-2.990, max=3.167, test: min=-1.919, max=2.288\n",
      ">104, train: min=-3.172, max=3.525, test: min=-2.000, max=3.071\n",
      ">105, train: min=-2.561, max=4.298, test: min=-2.235, max=2.443\n",
      ">106, train: min=-3.042, max=3.700, test: min=-3.236, max=2.064\n",
      ">107, train: min=-3.473, max=3.521, test: min=-2.637, max=2.312\n",
      ">108, train: min=-3.096, max=4.113, test: min=-2.500, max=2.413\n",
      ">109, train: min=-3.282, max=2.733, test: min=-2.839, max=2.210\n",
      ">110, train: min=-3.834, max=3.930, test: min=-2.960, max=3.439\n",
      ">111, train: min=-2.825, max=4.236, test: min=-3.767, max=2.347\n",
      ">112, train: min=-3.435, max=2.885, test: min=-2.383, max=2.304\n",
      ">113, train: min=-2.505, max=3.282, test: min=-2.742, max=2.815\n",
      ">114, train: min=-3.652, max=3.259, test: min=-2.460, max=2.184\n",
      ">115, train: min=-3.343, max=2.878, test: min=-2.691, max=2.064\n",
      ">116, train: min=-3.111, max=2.750, test: min=-1.693, max=2.412\n",
      ">117, train: min=-2.774, max=3.615, test: min=-1.749, max=2.051\n",
      ">118, train: min=-2.803, max=3.558, test: min=-2.324, max=4.260\n",
      ">119, train: min=-2.656, max=3.698, test: min=-2.505, max=2.437\n",
      ">120, train: min=-2.581, max=4.353, test: min=-1.739, max=4.347\n",
      ">121, train: min=-2.196, max=4.790, test: min=-2.566, max=2.584\n",
      ">122, train: min=-3.422, max=3.853, test: min=-2.541, max=2.192\n",
      ">123, train: min=-3.689, max=3.195, test: min=-2.932, max=1.685\n",
      ">124, train: min=-3.286, max=2.860, test: min=-2.424, max=2.922\n",
      ">125, train: min=-3.160, max=2.988, test: min=-2.126, max=1.893\n",
      ">126, train: min=-3.086, max=3.321, test: min=-1.814, max=2.719\n",
      ">127, train: min=-2.598, max=3.701, test: min=-2.964, max=2.379\n",
      ">128, train: min=-3.586, max=2.999, test: min=-2.329, max=3.187\n",
      ">129, train: min=-3.300, max=5.495, test: min=-2.562, max=2.194\n",
      ">130, train: min=-2.856, max=2.674, test: min=-2.981, max=1.359\n",
      ">131, train: min=-2.843, max=3.698, test: min=-2.297, max=2.403\n",
      ">132, train: min=-2.763, max=3.758, test: min=-2.693, max=3.460\n",
      ">133, train: min=-3.825, max=3.923, test: min=-3.893, max=1.907\n",
      ">134, train: min=-2.446, max=3.091, test: min=-2.864, max=2.648\n",
      ">135, train: min=-2.620, max=3.271, test: min=-2.267, max=3.424\n",
      ">136, train: min=-2.786, max=3.720, test: min=-2.253, max=2.239\n",
      ">137, train: min=-2.935, max=3.422, test: min=-2.079, max=2.473\n",
      ">138, train: min=-2.633, max=4.113, test: min=-2.256, max=2.935\n",
      ">139, train: min=-2.482, max=5.602, test: min=-1.599, max=3.703\n",
      ">140, train: min=-3.662, max=4.366, test: min=-2.300, max=2.882\n",
      ">141, train: min=-3.052, max=4.745, test: min=-1.833, max=3.776\n",
      ">142, train: min=-2.804, max=3.996, test: min=-2.366, max=2.192\n",
      ">143, train: min=-2.578, max=3.772, test: min=-2.027, max=1.605\n",
      ">144, train: min=-2.762, max=3.189, test: min=-2.374, max=1.832\n",
      ">145, train: min=-2.979, max=3.657, test: min=-2.023, max=2.235\n",
      ">146, train: min=-2.546, max=5.889, test: min=-1.851, max=2.325\n",
      ">147, train: min=-3.017, max=2.874, test: min=-2.235, max=1.970\n",
      ">148, train: min=-3.863, max=3.924, test: min=-2.429, max=2.632\n",
      ">149, train: min=-2.465, max=6.850, test: min=-1.702, max=2.115\n",
      ">150, train: min=-3.251, max=4.428, test: min=-2.172, max=2.957\n",
      ">151, train: min=-2.863, max=5.037, test: min=-1.691, max=3.826\n",
      ">152, train: min=-2.936, max=3.254, test: min=-4.344, max=1.768\n",
      ">153, train: min=-3.147, max=3.136, test: min=-3.767, max=1.855\n",
      ">154, train: min=-3.246, max=3.114, test: min=-2.003, max=2.480\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled = pd.DataFrame(scaler.transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "# summarize the scale of each input variable\n",
    "for i in range(X_test.shape[1]):\n",
    "    print('>%d, train: min=%.3f, max=%.3f, test: min=%.3f, max=%.3f' %\n",
    "        (i, X_train_scaled.iloc[:, i].min(), X_train_scaled.iloc[:, i].max(),\n",
    "            X_test_scaled.iloc[:, i].min(), X_test_scaled.iloc[:, i].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_and_save_df(df_tmp, y_tmp, name_to_save):\n",
    "    assert df_tmp.shape[0] == y_tmp.shape[0], 'Dataframe shapes are different'\n",
    "    df_tmp = df_tmp.join(y_tmp)\n",
    "    assert df_tmp.shape[0] == y_tmp.shape[0], 'Something missed after join'\n",
    "    df_tmp.to_csv(name_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "join_and_save_df(X_train_scaled, y_train, 'adni_train_scaled_corrected.csv')\n",
    "join_and_save_df(X_test_scaled, y_test, 'adni_test_scaled_corrected.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.31818021e-16,  2.15336309e-16,  5.22492422e-16, -4.10547729e-16,\n",
       "       -1.48924176e-16,  3.03382697e-16,  5.77919719e-16,  8.84153442e-16,\n",
       "        5.52092779e-16,  1.43389832e-16, -2.52902768e-16,  3.58893848e-16,\n",
       "        1.92528102e-16,  1.12917396e-15,  3.42793937e-16,  4.26731493e-16,\n",
       "       -8.96228375e-16,  3.70297951e-16,  4.31008032e-16,  6.62108837e-16,\n",
       "       -3.13948263e-16,  1.92528102e-16,  1.55632472e-16, -1.41545050e-16,\n",
       "       -4.10547729e-16,  6.87935777e-16, -3.60906337e-16,  1.00624443e-16,\n",
       "        9.52578063e-17,  6.49027659e-17,  3.20321145e-17,  3.52856381e-16,\n",
       "       -6.78879578e-16, -8.25120435e-17,  0.00000000e+00,  8.13045502e-16,\n",
       "        1.70390724e-16,  5.64167712e-16,  3.36756470e-16,  3.89081181e-17,\n",
       "        2.81748441e-17,  1.08406067e-15,  9.69348804e-17, -1.38190902e-16,\n",
       "        1.10016058e-16,  3.79689566e-16, -1.14041036e-17,  5.29955401e-16,\n",
       "       -7.53341666e-16,  6.74183770e-16,  3.89081181e-17, -7.37912584e-17,\n",
       "        1.45570028e-16, -1.12699377e-16, -1.14041036e-17,  2.01248887e-17,\n",
       "        2.02590546e-16,  3.56881359e-16,  5.56788586e-17,  1.50768958e-16,\n",
       "       -8.90190909e-16,  5.58130246e-16,  3.49502233e-16,  2.75710975e-16,\n",
       "        1.81123998e-16,  1.48655844e-15, -4.89370209e-16,  4.02497773e-16,\n",
       "       -2.24075201e-08, -4.00572378e-09, -4.30103067e-10, -3.83125103e-08,\n",
       "       -4.25054272e-08, -1.49501272e-07, -3.16913951e-08, -1.65375150e-07,\n",
       "       -5.21497970e-08, -2.37219140e-07, -8.57810701e-08, -4.09362301e-08,\n",
       "       -7.44675474e-08, -1.47108136e-07, -2.34044510e-08, -1.34705501e-08,\n",
       "       -2.71178238e-08, -2.34684313e-08, -3.98661341e-08, -2.06943347e-08,\n",
       "        2.11365882e-08, -2.74131911e-08, -4.83198461e-08, -6.44069746e-08,\n",
       "       -3.12018630e-08, -1.64902222e-07, -6.23325793e-08,  1.89144082e-08,\n",
       "       -8.65074404e-08, -7.29824491e-08, -6.69343691e-09, -6.86997951e-09,\n",
       "       -8.71521924e-09, -4.73906063e-08, -5.53144717e-09,  1.05258291e-08,\n",
       "        7.86654027e-08, -2.84909533e-08, -5.58534064e-08, -1.97496090e-07,\n",
       "       -4.74677540e-08, -1.67172235e-07, -2.40327655e-08, -3.13896396e-07,\n",
       "       -9.39702936e-08, -8.44561067e-08, -1.03580280e-07, -9.37580145e-08,\n",
       "       -3.46859490e-08,  2.44801902e-09, -1.63937361e-08, -1.86791926e-08,\n",
       "       -8.24483408e-08, -1.88363435e-08, -1.54037793e-08, -9.43860962e-09,\n",
       "       -6.43176188e-08, -1.00651258e-07, -2.13362271e-09, -1.66473767e-07,\n",
       "       -6.20977264e-08,  1.25850162e-08, -7.13111797e-08, -3.10842071e-08,\n",
       "       -1.03189885e-08, -5.57149791e-09, -1.03149751e-09, -7.64962667e-08,\n",
       "       -3.36862989e-08, -8.19060308e-07,  1.89889044e-08,  6.27403565e-08,\n",
       "       -4.98954591e-08, -2.20234372e-08, -1.82996635e-07, -3.42192518e-08,\n",
       "       -3.39941189e-08, -4.88866110e-09, -3.73832657e-08, -9.58508811e-07,\n",
       "        2.38899158e-08,  3.69810620e-08, -4.57192545e-08, -2.29538149e-08,\n",
       "       -4.87744142e-08, -4.27348837e-08, -4.36097197e-09])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adni_train_scaler.joblib']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(scaler, 'adni_train_scaler.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking loading is correct (after restarting the kernel)\n",
    "import joblib\n",
    "scaler = joblib.load('adni_train_scaler.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.31818021e-16,  2.15336309e-16,  5.22492422e-16, -4.10547729e-16,\n",
       "       -1.48924176e-16,  3.03382697e-16,  5.77919719e-16,  8.84153442e-16,\n",
       "        5.52092779e-16,  1.43389832e-16, -2.52902768e-16,  3.58893848e-16,\n",
       "        1.92528102e-16,  1.12917396e-15,  3.42793937e-16,  4.26731493e-16,\n",
       "       -8.96228375e-16,  3.70297951e-16,  4.31008032e-16,  6.62108837e-16,\n",
       "       -3.13948263e-16,  1.92528102e-16,  1.55632472e-16, -1.41545050e-16,\n",
       "       -4.10547729e-16,  6.87935777e-16, -3.60906337e-16,  1.00624443e-16,\n",
       "        9.52578063e-17,  6.49027659e-17,  3.20321145e-17,  3.52856381e-16,\n",
       "       -6.78879578e-16, -8.25120435e-17,  0.00000000e+00,  8.13045502e-16,\n",
       "        1.70390724e-16,  5.64167712e-16,  3.36756470e-16,  3.89081181e-17,\n",
       "        2.81748441e-17,  1.08406067e-15,  9.69348804e-17, -1.38190902e-16,\n",
       "        1.10016058e-16,  3.79689566e-16, -1.14041036e-17,  5.29955401e-16,\n",
       "       -7.53341666e-16,  6.74183770e-16,  3.89081181e-17, -7.37912584e-17,\n",
       "        1.45570028e-16, -1.12699377e-16, -1.14041036e-17,  2.01248887e-17,\n",
       "        2.02590546e-16,  3.56881359e-16,  5.56788586e-17,  1.50768958e-16,\n",
       "       -8.90190909e-16,  5.58130246e-16,  3.49502233e-16,  2.75710975e-16,\n",
       "        1.81123998e-16,  1.48655844e-15, -4.89370209e-16,  4.02497773e-16,\n",
       "       -2.24075201e-08, -4.00572378e-09, -4.30103067e-10, -3.83125103e-08,\n",
       "       -4.25054272e-08, -1.49501272e-07, -3.16913951e-08, -1.65375150e-07,\n",
       "       -5.21497970e-08, -2.37219140e-07, -8.57810701e-08, -4.09362301e-08,\n",
       "       -7.44675474e-08, -1.47108136e-07, -2.34044510e-08, -1.34705501e-08,\n",
       "       -2.71178238e-08, -2.34684313e-08, -3.98661341e-08, -2.06943347e-08,\n",
       "        2.11365882e-08, -2.74131911e-08, -4.83198461e-08, -6.44069746e-08,\n",
       "       -3.12018630e-08, -1.64902222e-07, -6.23325793e-08,  1.89144082e-08,\n",
       "       -8.65074404e-08, -7.29824491e-08, -6.69343691e-09, -6.86997951e-09,\n",
       "       -8.71521924e-09, -4.73906063e-08, -5.53144717e-09,  1.05258291e-08,\n",
       "        7.86654027e-08, -2.84909533e-08, -5.58534064e-08, -1.97496090e-07,\n",
       "       -4.74677540e-08, -1.67172235e-07, -2.40327655e-08, -3.13896396e-07,\n",
       "       -9.39702936e-08, -8.44561067e-08, -1.03580280e-07, -9.37580145e-08,\n",
       "       -3.46859490e-08,  2.44801902e-09, -1.63937361e-08, -1.86791926e-08,\n",
       "       -8.24483408e-08, -1.88363435e-08, -1.54037793e-08, -9.43860962e-09,\n",
       "       -6.43176188e-08, -1.00651258e-07, -2.13362271e-09, -1.66473767e-07,\n",
       "       -6.20977264e-08,  1.25850162e-08, -7.13111797e-08, -3.10842071e-08,\n",
       "       -1.03189885e-08, -5.57149791e-09, -1.03149751e-09, -7.64962667e-08,\n",
       "       -3.36862989e-08, -8.19060308e-07,  1.89889044e-08,  6.27403565e-08,\n",
       "       -4.98954591e-08, -2.20234372e-08, -1.82996635e-07, -3.42192518e-08,\n",
       "       -3.39941189e-08, -4.88866110e-09, -3.73832657e-08, -9.58508811e-07,\n",
       "        2.38899158e-08,  3.69810620e-08, -4.57192545e-08, -2.29538149e-08,\n",
       "       -4.87744142e-08, -4.27348837e-08, -4.36097197e-09])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
